{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "sys.path.append(\"../../pyASBC/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluidvec import *\n",
    "import pyASBC\n",
    "asbc = pyASBC.Asbc5Corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_iter = asbc.iter_sentences()\n",
    "from itertools import islice\n",
    "sents = list(islice(sent_iter, 0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_x = sents[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3504, 20396, 217350)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compo_vocab = Vocabulary.load(\"../data/compo_vocab.pkl\")\n",
    "char_vocab = Vocabulary.load(\"../data/char_vocab.pkl\")\n",
    "word_vocab = Vocabulary.load(\"../data/word_vocab.pkl\")\n",
    "len(compo_vocab), len(char_vocab), len(word_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../data/word_mappings.pkl\", \"rb\") as fin:\n",
    "    word_mappings = pickle.load(fin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_mappings.update({\n",
    "    \"<UNK>\": {'compos': [0], 'chars': [0], 'word': 0},\n",
    "    \"<PAD>\": {'compos': [1], 'chars': [1], 'word': 1}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compos': [8], 'chars': [382], 'word': 230}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_mappings[\"我\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_iter = asbc.iter_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = list(islice(sent_iter, 0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('時間', ['：'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_data_item(sents[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'compos': [0], 'chars': [0], 'word': 0},\n",
       " [{'compos': [2, 3, 4, 5], 'chars': [2, 3], 'word': 4}])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_data_item(make_data_item(sents[0])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_item(sent_x, win=2):\n",
    "    items = []\n",
    "    for i in range(len(sent_x)):\n",
    "        target = \"\"\n",
    "        context = []\n",
    "        for cur in range(i-win, i+win+1):\n",
    "            if cur < 0 or cur >= len(sent_x):\n",
    "                context.append(\"<PAD>\")\n",
    "            elif cur == i:                \n",
    "                target = sent_x[cur][0]\n",
    "            else:\n",
    "                context.append(sent_x[cur][0])\n",
    "        items.append((target, context))\n",
    "    return items\n",
    "\n",
    "def encode_data_item(item_x):\n",
    "    target, context = item_x\n",
    "    if target in word_mappings:\n",
    "        target_idx = word_mappings[target]\n",
    "    else:\n",
    "        target_idx = word_mappings[\"<UNK>\"]\n",
    "    ctx_idxs = [word_mappings.get(x, word_mappings[\"<UNK>\"]) for x in context]        \n",
    "    return (target_idx, ctx_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cde64689ae94a919f2b59aea422e17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState(12345)\n",
    "word_idxs = np.arange(len(word_vocab))\n",
    "data_items = []\n",
    "counter = 0\n",
    "sent_iter = asbc.iter_sentences()\n",
    "permuted = rng.permutation(len(word_vocab))\n",
    "# sent_iter = islice(sent_iter, 0, 6000)\n",
    "\n",
    "for sent_i, sent_x in tqdm(enumerate(sent_iter)):\n",
    "    item_idxs = [encode_data_item(x) for x in make_data_item(sent_x)]\n",
    "    data_items.extend(item_idxs)\n",
    "    if (sent_i+1) % 20000 == 0:\n",
    "        counter = int((sent_i+1)/2e4)\n",
    "        fout = open(f\"../data/train_items/train_items_{counter:03d}.pkl\", \"wb\")\n",
    "        pickle.dump(data_items, fout)\n",
    "        data_items = []\n",
    "        fout.close()\n",
    "        \n",
    "if data_items:\n",
    "    counter = counter + 1\n",
    "    fout = open(f\"../data/train_items/train_items_{counter:03d}.pkl\", \"wb\")\n",
    "    pickle.dump(data_items, fout)\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
