{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluidvec import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from torch.optim import AdamW\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from fluidvec.dataset import TrainDataset, get_dataloader\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/train_items/train_items_001.pkl\", \"rb\") as fin:\n",
    "    items = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'由'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs.word_vocab.decode(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_由_'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs.char_vocab.decode(97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'compos': [67, 68, 69, 70, 48, 49], 'chars': [47, 125, 31], 'word': 77},\n",
       "  [{'compos': [8], 'chars': [97], 'word': 60},\n",
       "   {'compos': [119, 157, 107, 131, 8], 'chars': [122, 123, 124], 'word': 76},\n",
       "   {'compos': [67, 68, 69, 70, 158, 159], 'chars': [47, 125, 126], 'word': 78},\n",
       "   {'compos': [78, 160, 50, 52, 8], 'chars': [127, 35, 128], 'word': 79}]),\n",
       " ({'compos': [67, 68, 69, 70, 158, 159], 'chars': [47, 125, 126], 'word': 78},\n",
       "  [{'compos': [119, 157, 107, 131, 8], 'chars': [122, 123, 124], 'word': 76},\n",
       "   {'compos': [67, 68, 69, 70, 48, 49], 'chars': [47, 125, 31], 'word': 77},\n",
       "   {'compos': [78, 160, 50, 52, 8], 'chars': [127, 35, 128], 'word': 79},\n",
       "   {'compos': [55, 56, 8], 'chars': [37, 38], 'word': 20}])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items[100:102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cpu\n",
      "n_neg_sample:  3\n"
     ]
    }
   ],
   "source": [
    "vs = VocabSet.load()\n",
    "word_weights = [vs.word_vocab.freq[idx]**0.75 for idx in range(len(vs.word_vocab))]\n",
    "\n",
    "use_cuda = False and torch.cuda.is_available()\n",
    "model = FluidVecSG(len(vs.word_vocab), len(vs.char_vocab), 0, \n",
    "                   dim=6, n_neg_sample=3, weights=word_weights, use_cuda=use_cuda)\n",
    "optim = AdamW(model.parameters(), lr=1e-3)\n",
    "if use_cuda:\n",
    "    model.to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_dict = model.transform_batch_data(items[100:101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8685,  0.4740, -0.5630,  0.0669, -0.2706, -0.3580],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.char_emb(torch.tensor([47,125,31])).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tgt': tensor([[ 0.8685,  0.4740, -0.5630,  0.0669, -0.2706, -0.3580]],\n",
       "        grad_fn=<StackBackward>),\n",
       " 'ctx': tensor([[[ 0.1706, -1.1125, -1.5387,  2.0441, -0.2650,  0.7361],\n",
       "          [ 0.2482,  1.1317, -0.7563, -0.9331, -0.2241,  0.2972],\n",
       "          [-0.5176, -0.6282, -0.8034,  0.5513,  0.0451,  0.6017],\n",
       "          [ 0.5939,  0.6047,  1.1013,  1.3819,  0.3913,  0.5915]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " 'ctx_mask': tensor([[1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5939, 0.6047, 1.1013, 1.3819, 0.3913, 0.5915],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.word_emb(torch.tensor(79))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8685,  0.4740, -0.5630,  0.0669, -0.2706, -0.3580]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1706, -1.1125, -1.5387,  2.0441, -0.2650,  0.7361],\n",
       "         [ 0.2482,  1.1317, -0.7563, -0.9331, -0.2241,  0.2972],\n",
       "         [-0.5176, -0.6282, -0.8034,  0.5513,  0.0451,  0.6017],\n",
       "         [ 0.5939,  0.6047,  1.1013,  1.3819,  0.3913,  0.5915]]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6861, -0.1233, -0.4947, -1.4695, -1.4075, -0.9184],\n",
       "         [ 0.0946,  1.8954,  1.0712,  1.1584,  0.7281,  0.4916],\n",
       "         [-1.3748, -0.4124,  0.3517,  1.6456,  0.4747, -0.2277],\n",
       "         [-1.5799, -1.9747,  1.0651,  2.0222, -0.5379, -1.1553],\n",
       "         [ 1.1998, -0.8193,  1.0410, -1.2435,  0.1773,  0.4780],\n",
       "         [ 1.2114, -1.1760, -0.5726,  0.9438,  1.4270, -0.7126],\n",
       "         [ 0.1268,  0.9072, -0.4544,  1.9798,  0.1110, -0.7260],\n",
       "         [-0.8510,  1.5819, -0.1254, -1.4437, -0.0067, -0.2119],\n",
       "         [ 1.9090,  2.2520,  0.8745,  0.5411,  0.2419,  0.2300],\n",
       "         [ 0.6196,  0.6806,  1.0948,  0.2976, -0.4565,  0.0359],\n",
       "         [ 1.5301,  0.2887,  0.5422, -0.1980,  0.0766, -0.4669],\n",
       "         [ 0.4405, -0.2741,  1.0912,  0.4701,  0.5924,  0.1188]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6331, -0.0819,  1.5244,  2.2135,  0.2346, -0.7493, -1.1583, -0.0623,\n",
       "         -2.1215, -0.3749, -1.2937,  0.5331]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tgt.unsqueeze(1)*noise_vec).neg().sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6331, -0.0819,  1.5244,  2.2135,  0.2346, -0.7493, -1.1583, -0.0623,\n",
       "         -2.1215, -0.3749, -1.2937,  0.5331]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tgt.unsqueeze(1)*noise_vec.neg()).sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6331],\n",
       "         [-0.0819],\n",
       "         [ 1.5244],\n",
       "         [ 2.2135],\n",
       "         [ 0.2346],\n",
       "         [-0.7493],\n",
       "         [-1.1583],\n",
       "         [-0.0623],\n",
       "         [-2.1215],\n",
       "         [-0.3749],\n",
       "         [-1.2937],\n",
       "         [ 0.5331]]], grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(noise_vec.neg(), tgt.unsqueeze(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = vec_dict[\"tgt\"] # (batch_size, dim)\n",
    "ctx = vec_dict[\"ctx\"] # (batch_size, win_size, dim)\n",
    "mask = vec_dict[\"ctx_mask\"] # (batch_size, win_size)\n",
    "\n",
    "batch_size = ctx.size(0)\n",
    "win_size = ctx.size(1)\n",
    "n_noise = batch_size * win_size * model.n_neg_sample\n",
    "draw = torch.multinomial(model.weights, n_noise, True)\n",
    "noise = draw.view(batch_size, win_size*model.n_neg_sample)\n",
    "# noise = noise.to(self.device)\n",
    "noise_vec = model.word_emb(noise)  # (batch_size, win_size*n_neg, dim)\n",
    "\n",
    "log_target = ((tgt.unsqueeze(1) * ctx).sum(2).sigmoid()+1e-5).log()\n",
    "log_target = log_target * mask\n",
    "log_target_val = log_target.sum()        \n",
    "\n",
    "sum_log_noise = ((tgt.unsqueeze(1)*noise_vec)\n",
    "                .neg().sum(2).sigmoid()+1e-5).log()\n",
    "sum_log_noise = (sum_log_noise.view(batch_size, win_size, -1)\n",
    "                 * mask.unsqueeze(2)).view(batch_size, -1)\n",
    "sum_log_noise_val = sum_log_noise.sum()        \n",
    "loss = log_target_val + sum_log_noise_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-12.9421, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
